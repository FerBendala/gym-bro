from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
import requests
import json

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="GPT Training Assistant (Fast)", version="1.0.0")

# Configurar CORS para permitir conexiones desde React
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173", 
        "http://127.0.0.1:5173",
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "*"
    ],
    allow_credentials=False,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# Modelo de datos
class ChatRequest(BaseModel):
    message: str
    reasoning_level: str = "medium"
    context: str = ""

class ChatResponse(BaseModel):
    response: str
    error: str = None

# Configuraci√≥n de Ollama
OLLAMA_URL = "http://localhost:11434"
MODEL_NAME = "gpt-oss:20b"

def check_ollama_available():
    """Verificar si Ollama est√° disponible"""
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags")
        return response.status_code == 200
    except:
        return False

def generate_response_with_ollama(prompt: str) -> str:
    """Generar respuesta usando Ollama optimizada para velocidad"""
    try:
        payload = {
            "model": MODEL_NAME,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "num_predict": 1024,  # Optimizado para GPT-OSS-20B
                "top_k": 40,
                "repeat_penalty": 1.1,
                "mirostat": 2,
                "mirostat_tau": 5.0,
                "mirostat_eta": 0.1
            }
        }
        
        response = requests.post(f"{OLLAMA_URL}/api/generate", json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            return result.get("response", "No se pudo generar una respuesta")
        else:
            logger.error(f"Error en Ollama: {response.status_code} - {response.text}")
            return "Error al generar respuesta"
            
    except Exception as e:
        logger.error(f"Error comunic√°ndose con Ollama: {e}")
        return f"Error de conexi√≥n: {str(e)}"

@app.get("/")
async def root():
    return {"message": "GPT Training Assistant API (Fast)", "status": "running"}

@app.get("/health")
async def health_check():
    ollama_available = check_ollama_available()
    return {
        "status": "healthy" if ollama_available else "unhealthy",
        "model_loaded": ollama_available,
        "mode": "fast_ai",
        "model": MODEL_NAME
    }

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Endpoint principal para chat con el modelo optimizado"""
    try:
        logger.info(f"Procesando mensaje: {request.message}")
        logger.info(f"Contexto recibido: {request.context[:200] if request.context else 'Sin contexto'}...")
        
        reasoning_level = request.reasoning_level

        # Prompt optimizado para respuestas completas y en espa√±ol
        if request.context:
            enhanced_prompt = f"""
[INST] Eres un entrenador personal experto llamado "GymBro" que conoce perfectamente el entrenamiento de tu cliente. Tienes acceso a todos sus datos de entrenamiento, ejercicios, y progreso.

Reasoning: {reasoning_level}

CONTEXTO DEL USUARIO:
{request.context}

PREGUNTA: {request.message}

IMPORTANTE: 
- Act√∫a como su entrenador personal que conoce cada detalle de su rutina
- Usa SIEMPRE los datos reales del contexto para responder
- Si pregunta "qu√© ejercicios he hecho hoy", responde SOLO con los entrenamientos REALES de hoy
- Si no hay entrenamientos hoy, di claramente "No has hecho entrenamientos hoy"
- Si hay entrenamientos, lista espec√≠ficamente cada ejercicio con peso, reps y sets
- Habla en segunda persona ("has hecho", "tu entrenamiento", "tu progreso")
- S√© espec√≠fico con los datos: pesos, repeticiones, series, fechas
- NO inventes ejercicios que no est√°n en los datos
- NO mezcles ejercicios programados con ejercicios realizados
- Proporciona an√°lisis detallado y recomendaciones personalizadas
- Usa el reasoning level para ajustar la profundidad de tu respuesta

Responde √∫nicamente en espa√±ol y aseg√∫rate de completar todas las ideas. Termina tu respuesta con un punto final. [/INST]
"""
        else:
            enhanced_prompt = f"""
[INST] Eres un entrenador personal experto llamado "GymBro". Responde SOLO EN ESPA√ëOL de manera clara y directa.

Reasoning: {reasoning_level}

PREGUNTA: {request.message}

IMPORTANTE:
- Act√∫a como un entrenador personal profesional
- Habla en segunda persona ("tu entrenamiento", "tu progreso")
- S√© espec√≠fico y pr√°ctico
- NO inventes datos que no tienes
- Si no tienes informaci√≥n espec√≠fica, dilo claramente
- Usa el reasoning level para ajustar la profundidad de tu respuesta

Responde √∫nicamente en espa√±ol y aseg√∫rate de completar todas las ideas. Termina tu respuesta con un punto final. [/INST]
"""

        # Generar respuesta usando Ollama
        response = generate_response_with_ollama(enhanced_prompt)
        
        return ChatResponse(response=response)
        
    except Exception as e:
        logger.error(f"Error procesando mensaje: {e}")
        return ChatResponse(response="", error=str(e))

@app.post("/analyze-training", response_model=ChatResponse)
async def analyze_training_data(request: ChatRequest):
    """Endpoint espec√≠fico para an√°lisis de datos de entrenamiento"""
    try:
        analysis_prompt = f"""
[INST] Eres un experto en entrenamiento f√≠sico. Analiza estos datos y proporciona insights √∫tiles EN ESPA√ëOL:

{request.message}

Proporciona EN ESPA√ëOL:
1. An√°lisis del progreso
2. Patrones identificados
3. Recomendaciones espec√≠ficas
4. Ajustes sugeridos
5. Consejos de optimizaci√≥n

S√© espec√≠fico y pr√°ctico. Responde √∫nicamente en espa√±ol. [/INST]
"""

        logger.info(f"Analizando datos de entrenamiento")
        
        # Generar an√°lisis usando Ollama
        response = generate_response_with_ollama(analysis_prompt)
        
        return ChatResponse(response=response)
        
    except Exception as e:
        logger.error(f"Error analizando datos: {e}")
        return ChatResponse(response="", error=str(e))

if __name__ == "__main__":
    import uvicorn
    print("ÔøΩÔøΩ Iniciando servidor GPT-OSS en http://localhost:8004")
    print(f"üß† Usando modelo: {MODEL_NAME}")
    print("‚ö° Optimizado para respuestas inteligentes y reasoning")
    print("üá™üá∏ Todas las respuestas en espa√±ol")
    print("üéØ Reasoning levels: low, medium, high")
    uvicorn.run(app, host="0.0.0.0", port=8004, reload=False) 